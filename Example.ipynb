{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as Func\n",
    "from torch.nn import init\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from numpy import linalg as LA\n",
    "import networkx as nx\n",
    "\n",
    "from utils import *\n",
    "from metrics import *\n",
    "import pickle\n",
    "import argparse\n",
    "from torch import autograd\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from model import *\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "parser.add_argument('--input_size', type=int, default=2)\n",
    "parser.add_argument('--output_size', type=int, default=5)\n",
    "parser.add_argument('--n_stgcnn', type=int, default=1)\n",
    "parser.add_argument('--kernel_size', type=int, default=3)\n",
    "parser.add_argument('--num_channels', type=list, default=[14,12,10])\n",
    "\n",
    "parser.add_argument('--obs_seq_len', type=int, default=20)\n",
    "parser.add_argument('--pred_seq_len', type=int, default=10)\n",
    "parser.add_argument('--dataset', default='Data1')\n",
    "parser.add_argument('--dataset1', default='Data2')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=128,\n",
    "                    help='minibatch size')\n",
    "parser.add_argument('--num_epochs', type=int, default=150,\n",
    "                    help='number of epochs')\n",
    "parser.add_argument('--clip_grad', type=float, default=None)\n",
    "parser.add_argument('--lr', type=float, default=0.01,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--lr_sh_rate', type=int, default=50)\n",
    "parser.add_argument('--use_lrschd', action=\"store_true\", default=False)\n",
    "parser.add_argument('--tag', default='20-10')\n",
    "args = parser.parse_args(args=[])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('*' * 30)\n",
    "print(\"Training initiating....\")\n",
    "print(args)\n",
    "\n",
    "\n",
    "def graph_loss(V_pred, V_target):\n",
    "    return bivariate_loss(V_pred, V_target)\n",
    "size_list_path_ves = './datasets/ves.txt'\n",
    "\n",
    "# Data prep\n",
    "obs_seq_len = args.obs_seq_len\n",
    "pred_seq_len = args.pred_seq_len\n",
    "data_set = './datasets/' + args.dataset + '/'\n",
    "data_set1 = './datasets/' + args.dataset1 + '/'\n",
    "dset_train = TrajectoryDataset(\n",
    "    data_set + 'train/',\n",
    "    data_set1 + 'train/',\n",
    "    size_list_path_ves,\n",
    "    obs_len=obs_seq_len,\n",
    "    pred_len=pred_seq_len,\n",
    "    skip=1, norm_lap_matr=True)\n",
    "torch.save(dset_train, \"./datasets/dset_train20-10.pt\")\n",
    "dset_train = torch.load(\"./datasets/dset_train20-10.pt\")\n",
    "\n",
    "loader_train = DataLoader(\n",
    "    dset_train,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "\n",
    "dset_val = TrajectoryDataset(\n",
    "    data_set + 'val/',\n",
    "    data_set1 + 'val/',\n",
    "    size_list_path_ves,\n",
    "    obs_len=obs_seq_len,\n",
    "    pred_len=pred_seq_len,\n",
    "    skip=1, norm_lap_matr=True)\n",
    "torch.save(dset_val, \"./datasets/dset_val20-10.pt\")\n",
    "dset_val = torch.load(\"./datasets/dset_val20-10.pt\")\n",
    "loader_val = DataLoader(\n",
    "    dset_val,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=1)\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "model = social_stgcnn(n_stgcnn=args.n_stgcnn,\n",
    "                      output_feat=args.output_size, seq_len=args.obs_seq_len,\n",
    "                      kernel_size=args.kernel_size, pred_seq_len=args.pred_seq_len)\n",
    "\n",
    "# Training settings\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "if args.use_lrschd:\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_sh_rate, gamma=0.2)\n",
    "\n",
    "checkpoint_dir = './checkpoint/' + args.tag + '/'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "with open(checkpoint_dir + 'args.pkl', 'wb') as fp:\n",
    "    pickle.dump(args, fp)\n",
    "\n",
    "print('Data and model loaded')\n",
    "print('Checkpoint dir:', checkpoint_dir)\n",
    "\n",
    "# Training\n",
    "metrics = {'train_loss': [], 'val_loss': []}\n",
    "constant_metrics = {'min_val_epoch': -1, 'min_val_loss': 9999999999999999}\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global metrics, loader_train\n",
    "    model.train()\n",
    "    loss_batch = 0\n",
    "    batch_count = 0\n",
    "    is_fst_loss = True\n",
    "    loader_len = len(loader_train)\n",
    "    turn_point = int(loader_len / args.batch_size) * args.batch_size + loader_len % args.batch_size - 1\n",
    "\n",
    "    for cnt, batch in enumerate(loader_train):\n",
    "        batch_count += 1\n",
    "\n",
    "        # Get data\n",
    "        batch = [tensor.to(device) for tensor in batch]\n",
    "        obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped, \\\n",
    "        loss_mask, V_obs, A_obs, V_tr, A_tr, A_DPCA_obs, A_DPCA_tr, A_TPCA_obs, A_TPCA_tr, \\\n",
    "        A_vs_obs, A_vs_tr,A_sim_obs, A_sim_tr = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        V_obs_tmp = V_obs.permute(0, 3, 1, 2)\n",
    "\n",
    "        V_pred, _ = model(V_obs_tmp, A_obs.squeeze(), A_DPCA_obs.squeeze(), A_TPCA_obs.squeeze(), A_vs_obs.squeeze(), A_sim_obs.squeeze())\n",
    "\n",
    "        V_pred = V_pred.permute(0, 2, 3, 1)\n",
    "\n",
    "        V_tr = V_tr.squeeze()\n",
    "        A_tr = A_tr.squeeze()\n",
    "        V_pred = V_pred.squeeze()\n",
    "\n",
    "        if batch_count % args.batch_size != 0 and cnt != turn_point:\n",
    "            l = graph_loss(V_pred, V_tr)\n",
    "            if is_fst_loss:\n",
    "                loss = l\n",
    "                is_fst_loss = False\n",
    "            else:\n",
    "                loss += l\n",
    "\n",
    "        else:\n",
    "            loss = loss / args.batch_size\n",
    "            is_fst_loss = True\n",
    "            loss.backward()\n",
    "\n",
    "            if args.clip_grad is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_grad)\n",
    "\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            loss_batch += loss.item()\n",
    "            print('TRAIN:', '\\t Epoch:', epoch, '\\t Loss:', loss_batch / batch_count)\n",
    "\n",
    "    metrics['train_loss'].append(loss_batch / batch_count)\n",
    "\n",
    "\n",
    "def vald(epoch):\n",
    "    global metrics, loader_val, constant_metrics\n",
    "    model.eval()\n",
    "    loss_batch = 0\n",
    "    batch_count = 0\n",
    "    is_fst_loss = True\n",
    "    loader_len = len(loader_val)\n",
    "    turn_point = int(loader_len / args.batch_size) * args.batch_size + loader_len % args.batch_size - 1\n",
    "\n",
    "    for cnt, batch in enumerate(loader_val):\n",
    "        batch_count += 1\n",
    "\n",
    "        # Get data\n",
    "        batch = [tensor.to(device) for tensor in batch]\n",
    "        obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped, \\\n",
    "        loss_mask, V_obs, A_obs, V_tr, A_tr, A_DPCA_obs, A_DPCA_tr, A_TPCA_obs, A_TPCA_tr,\\\n",
    "        A_vs_obs, A_vs_tr,A_sim_obs, A_sim_tr = batch\n",
    "\n",
    "        V_obs_tmp = V_obs.permute(0, 3, 1, 2)\n",
    "\n",
    "        V_pred, _ = model(V_obs_tmp, A_obs.squeeze(), A_DPCA_obs.squeeze(), A_TPCA_obs.squeeze(), A_vs_obs.squeeze(), A_sim_obs.squeeze())\n",
    "\n",
    "        V_pred = V_pred.permute(0, 2, 3, 1)\n",
    "\n",
    "        V_tr = V_tr.squeeze()\n",
    "        A_tr = A_tr.squeeze()\n",
    "        V_pred = V_pred.squeeze()\n",
    "\n",
    "        if batch_count % args.batch_size != 0 and cnt != turn_point:\n",
    "            l = graph_loss(V_pred, V_tr)\n",
    "            if is_fst_loss:\n",
    "                loss = l\n",
    "                is_fst_loss = False\n",
    "            else:\n",
    "                loss += l\n",
    "\n",
    "        else:\n",
    "            loss = loss / args.batch_size\n",
    "            is_fst_loss = True\n",
    "            # Metrics\n",
    "            loss_batch += loss.item()\n",
    "            print('VALD:', '\\t Epoch:', epoch, '\\t Loss:', loss_batch / batch_count)\n",
    "\n",
    "    metrics['val_loss'].append(loss_batch / batch_count)\n",
    "\n",
    "    if metrics['val_loss'][-1] < constant_metrics['min_val_loss']:\n",
    "        constant_metrics['min_val_loss'] = metrics['val_loss'][-1]\n",
    "        constant_metrics['min_val_epoch'] = epoch\n",
    "        torch.save(model.state_dict(), checkpoint_dir + 'val_best.pth')  # OK\n",
    "\n",
    "\n",
    "print('Training started ...')\n",
    "for epoch in range(args.num_epochs):\n",
    "    train(epoch)\n",
    "    vald(epoch)\n",
    "    if args.use_lrschd:\n",
    "        scheduler.step()\n",
    "\n",
    "    print('*' * 30)\n",
    "    print('Epoch:', args.tag, \":\", epoch)\n",
    "    for k, v in metrics.items():\n",
    "        if len(v) > 0:\n",
    "            print(k, v[-1])\n",
    "\n",
    "    print(constant_metrics)\n",
    "    print('*' * 30)\n",
    "\n",
    "    with open(checkpoint_dir + 'metrics.pkl', 'wb') as fp:\n",
    "        pickle.dump(metrics, fp)\n",
    "\n",
    "    with open(checkpoint_dir + 'constant_metrics.pkl', 'wb') as fp:\n",
    "        pickle.dump(constant_metrics, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63acf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import argparse\n",
    "import glob\n",
    "import torch.distributions.multivariate_normal as torchdist\n",
    "from utils import * \n",
    "from metrics import * \n",
    "from model import social_stgcnn\n",
    "import copy\n",
    "dset_test = TrajectoryDataset(\n",
    "        data_set+'test/',\n",
    "        data_set1+'test/',\n",
    "        size_list_path_ves,\n",
    "        obs_len=obs_seq_len,\n",
    "        pred_len=pred_seq_len,\n",
    "        skip=1,norm_lap_matr=True)\n",
    "\n",
    "loader_test = DataLoader(\n",
    "        dset_test,\n",
    "        batch_size=1,\n",
    "        shuffle =False,\n",
    "        num_workers=1)\n",
    "torch.save(dset_test, \"./datasets/dset_test20-10.pt\")\n",
    "def test(KSTEPS=20):\n",
    "    global loader_test,model\n",
    "    model.eval()\n",
    "    ade_bigls = []\n",
    "    fde_bigls = []\n",
    "    raw_data_dict = {}\n",
    "    step =0 \n",
    "    for batch in loader_test: \n",
    "        step+=1\n",
    "        #Get data\n",
    "        batch = [tensor.to(device) for tensor in batch]\n",
    "        obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped, \\\n",
    "        loss_mask, V_obs, A_obs, V_tr, A_tr, A_DPCA_obs, A_DPCA_tr, A_TPCA_obs, A_TPCA_tr,\\\n",
    "        A_vs_obs, A_vs_tr,A_sim_obs, A_sim_tr  = batch\n",
    "\n",
    "\n",
    "        num_of_objs = obs_traj_rel.shape[1]\n",
    "\n",
    "        #Forward\n",
    "        #V_obs = batch,seq,node,feat\n",
    "        #V_obs_tmp = batch,feat,seq,node\n",
    "        V_obs_tmp =V_obs.permute(0,3,1,2)\n",
    "\n",
    "        V_pred,_ = model(V_obs_tmp,A_obs.squeeze(),A_DPCA_obs.squeeze(),A_TPCA_obs.squeeze(),A_vs_obs.squeeze(),A_sim_obs.squeeze())\n",
    "        V_pred = V_pred.permute(0,2,3,1)\n",
    "\n",
    "        V_tr = V_tr.squeeze()\n",
    "        A_tr = A_tr.squeeze()\n",
    "        V_pred = V_pred.squeeze()\n",
    "        num_of_objs = obs_traj_rel.shape[1]\n",
    "        V_pred,V_tr =  V_pred[:,:num_of_objs,:],V_tr[:,:num_of_objs,:]\n",
    "\n",
    "        sx = torch.exp(V_pred[:,:,2]) #sx\n",
    "        sy = torch.exp(V_pred[:,:,3]) #sy\n",
    "        corr = torch.tanh(V_pred[:,:,4]) #corr\n",
    "        \n",
    "        cov = torch.zeros(V_pred.shape[0],V_pred.shape[1],2,2)\n",
    "        cov[:,:,0,0]= sx*sx\n",
    "        cov[:,:,0,1]= corr*sx*sy\n",
    "        cov[:,:,1,0]= corr*sx*sy\n",
    "        cov[:,:,1,1]= sy*sy\n",
    "        mean = V_pred[:,:,0:2]\n",
    "        mvnormal = torchdist.MultivariateNormal(mean,cov)\n",
    "        \n",
    "        #Now sample 20 samples\n",
    "        ade_ls = {}\n",
    "        fde_ls = {}\n",
    "\n",
    "        V_x = seq_to_nodes(obs_traj.data.cpu().numpy().copy())\n",
    "        V_x_rel_to_abs = nodes_rel_to_nodes_abs(V_obs.data.cpu().numpy().squeeze().copy(),\n",
    "                                                 V_x[0,:,:].copy())\n",
    "\n",
    "        V_y = seq_to_nodes(pred_traj_gt.data.cpu().numpy().copy())\n",
    "        V_y_rel_to_abs = nodes_rel_to_nodes_abs(V_tr.data.cpu().numpy().squeeze().copy(),\n",
    "                                                 V_x[-1,:,:].copy())\n",
    "        \n",
    "        raw_data_dict[step] = {}\n",
    "        raw_data_dict[step]['obs'] = copy.deepcopy(V_x_rel_to_abs)\n",
    "        raw_data_dict[step]['trgt'] = copy.deepcopy(V_y_rel_to_abs)\n",
    "        raw_data_dict[step]['pred'] = []\n",
    "\n",
    "        for n in range(num_of_objs):\n",
    "            ade_ls[n]=[]\n",
    "            fde_ls[n]=[]\n",
    "\n",
    "        for k in range(KSTEPS):\n",
    "\n",
    "            V_pred = mvnormal.sample()\n",
    "\n",
    "            V_pred_rel_to_abs = nodes_rel_to_nodes_abs(V_pred.data.cpu().numpy().squeeze().copy(),\n",
    "                                                     V_x[-1,:,:].copy())\n",
    "            raw_data_dict[step]['pred'].append(copy.deepcopy(V_pred_rel_to_abs))\n",
    "            \n",
    "            for n in range(num_of_objs):\n",
    "                pred = [] \n",
    "                target = []\n",
    "                obsrvs = [] \n",
    "                number_of = []\n",
    "                pred.append(V_pred_rel_to_abs[:,n:n+1,:])\n",
    "                target.append(V_y_rel_to_abs[:,n:n+1,:])\n",
    "                obsrvs.append(V_x_rel_to_abs[:,n:n+1,:])\n",
    "                number_of.append(1)\n",
    "\n",
    "                ade_ls[n].append(ade(pred,target,number_of))\n",
    "                fde_ls[n].append(fde(pred,target,number_of))\n",
    "        \n",
    "        for n in range(num_of_objs):\n",
    "            ade_bigls.append(min(ade_ls[n]))\n",
    "            fde_bigls.append(min(fde_ls[n]))\n",
    "\n",
    "    ade_ = sum(ade_bigls)/len(ade_bigls)\n",
    "    fde_ = sum(fde_bigls)/len(fde_bigls)\n",
    "    return ade_,fde_,raw_data_dict\n",
    "\n",
    "\n",
    "paths = ['./checkpoint/*social-stgcnn*']\n",
    "KSTEPS=20\n",
    "\n",
    "print(\"*\"*50)\n",
    "print('Number of samples:',KSTEPS)\n",
    "print(\"*\"*50)\n",
    "ade_ls = [] \n",
    "fde_ls = [] \n",
    "path = paths[-1]\n",
    "exps = './checkpoint/20-10/'\n",
    "print('Model being tested are:',exps)\n",
    "\n",
    "exp_path = exps\n",
    "print(\"*\"*50)\n",
    "print(\"Evaluating model:\",exp_path)\n",
    "\n",
    "model_path = exp_path+'/val_best.pth'\n",
    "args_path = exp_path+'/args.pkl'\n",
    "with open(args_path,'rb') as f: \n",
    "    args = pickle.load(f)\n",
    "\n",
    "stats= exp_path+'/constant_metrics.pkl'\n",
    "with open(stats,'rb') as f: \n",
    "    cm = pickle.load(f)\n",
    "print(\"Stats:\",cm)\n",
    "\n",
    "\n",
    "\n",
    "#Data prep     \n",
    "obs_seq_len = args.obs_seq_len\n",
    "pred_seq_len = args.pred_seq_len\n",
    "data_set = './datasets/'+args.dataset+'/'\n",
    "\n",
    "\n",
    "dset_test = torch.load(\"./datasets/dset_test20-10.pt\")\n",
    "loader_test = DataLoader(\n",
    "        dset_test,\n",
    "        batch_size=1,\n",
    "        shuffle =False,\n",
    "        num_workers=1)\n",
    "\n",
    "\n",
    "\n",
    "#Defining the model \n",
    "model = social_stgcnn(n_stgcnn =args.n_stgcnn,\n",
    "output_feat=args.output_size,seq_len=args.obs_seq_len,\n",
    "kernel_size=args.kernel_size,pred_seq_len=args.pred_seq_len)\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "\n",
    "ade_ =999999\n",
    "fde_ =999999\n",
    "print(\"Testing ....\")\n",
    "ad,fd,raw_data_dic_= test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ade(forecasted_trajectory_Lon,forecasted_trajectory_Lat,gt_trajectory_Lon,gt_trajectory_Lat):\n",
    "    pred_len = forecasted_trajectory_Lon.shape[0]\n",
    "    ade = float(\n",
    "        sum(\n",
    "            math.sqrt(\n",
    "                (forecasted_trajectory_Lon[i] - gt_trajectory_Lon[i]) ** 2\n",
    "                + (forecasted_trajectory_Lat[i] - gt_trajectory_Lat[i]) ** 2\n",
    "            )\n",
    "            for i in range(pred_len)\n",
    "        )\n",
    "        / pred_len\n",
    "    )\n",
    "    return ade\n",
    "def get_fde(forecasted_trajectory_Lon,forecasted_trajectory_Lat,gt_trajectory_Lon,gt_trajectory_Lat):\n",
    "    fde = math.sqrt( #单条轨迹中最后一个轨迹点坐标与真值的欧氏距离\n",
    "        (forecasted_trajectory_Lon[-1] - gt_trajectory_Lon[-1]) ** 2  \n",
    "        + (forecasted_trajectory_Lat[-1] - gt_trajectory_Lat[-1]) ** 2\n",
    "    )\n",
    "    return fde\n",
    "ade = []\n",
    "fde = []\n",
    "for i in range(0,3):\n",
    "    ade1 = []\n",
    "    fde1 = []\n",
    "    for a in range(1,len(raw_data_dic_)):\n",
    "        tag = np.array(raw_data_dic_[a]['trgt'])\n",
    "        pre = np.array(raw_data_dic_[a]['pred'])\n",
    "        x2 = []\n",
    "        x3 = []\n",
    "        for j in range(0,20):\n",
    "            x2.append(get_ade(pre[j,:,i,0],pre[j,:,i,1],tag[:,i,0],tag[:,i,1]))\n",
    "            x3.append(get_fde(pre[j,:,i,0],pre[j,:,i,1],tag[:,i,0],tag[:,i,1]))\n",
    "        ade1.append(x2)\n",
    "        fde1.append(x3)\n",
    "    ade.append(ade1)\n",
    "    fde.append(fde1)\n",
    "print('mean',np.array(ade).flatten().mean())\n",
    "print('std',np.array(ade).flatten().std())\n",
    "print('mean',np.array(fde).flatten().mean())\n",
    "print('std',np.array(fde).flatten().std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
